{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Off-Peak Simulator Lite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the controls below to explore how shifting riders from peak to off-peak periods changes demand, load factors, and revenue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import math\n",
        "from datetime import datetime, timedelta\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import display, clear_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.style.use('seaborn-v0_8') if 'seaborn-v0_8' in plt.style.available else None\n",
        "DATA_PATH = Path('data')\n",
        "PROCESSED_PATH = DATA_PATH / 'processed'\n",
        "RIDERSHIP_CSV = DATA_PATH / 'ridership.csv'\n",
        "PROCESSED_PATH.mkdir(parents=True, exist_ok=True)\n",
        "BASELINE_WEEKS = 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fabricate_synthetic_data(path: Path, weeks: int = 12, freq_minutes: int = 15) -> pd.DataFrame:\n",
        "    start = pd.Timestamp('2025-01-06 00:00:00')\n",
        "    periods = weeks * 7 * (24 * 60 // freq_minutes)\n",
        "    index = pd.date_range(start=start, periods=periods, freq=f'{freq_minutes}T')\n",
        "\n",
        "    rng = np.random.default_rng(42)\n",
        "    weekend_scale = {5: 0.7, 6: 0.6}\n",
        "\n",
        "    def daily_pattern(ts: pd.Timestamp) -> float:\n",
        "        hour_decimal = ts.hour + ts.minute / 60\n",
        "        base = 80\n",
        "        morning_peak = 200 * math.exp(-0.5 * ((hour_decimal - 8) / 1.5) ** 2)\n",
        "        evening_peak = 180 * math.exp(-0.5 * ((hour_decimal - 18) / 1.8) ** 2)\n",
        "        offpeak = 40 * math.cos((hour_decimal - 12) / 12 * math.pi) + 40\n",
        "        return base + morning_peak + evening_peak + offpeak\n",
        "\n",
        "    riders = []\n",
        "    for ts in index:\n",
        "        base_demand = daily_pattern(ts)\n",
        "        factor = weekend_scale.get(ts.dayofweek, 1.0)\n",
        "        noise = rng.normal(0, 8)\n",
        "        weather = rng.normal(0, 5) if rng.random() < 0.3 else 0\n",
        "        riders.append(max(20, int(base_demand * factor + noise + weather)))\n",
        "\n",
        "    df = pd.DataFrame({'timestamp': index, 'riders': riders})\n",
        "    df.to_csv(path, index=False)\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_or_generate(path: Path) -> pd.DataFrame:\n",
        "    if path.exists():\n",
        "        df = pd.read_csv(path, parse_dates=['timestamp'])\n",
        "    else:\n",
        "        df = fabricate_synthetic_data(path)\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def infer_frequency_minutes(df: pd.DataFrame) -> int:\n",
        "    diffs = df['timestamp'].diff().dropna()\n",
        "    if diffs.empty:\n",
        "        return 60\n",
        "    mode = diffs.mode().iloc[0]\n",
        "    return int(mode.total_seconds() // 60) or 60\n",
        "\n",
        "\n",
        "data = load_or_generate(RIDERSHIP_CSV)\n",
        "freq_minutes = infer_frequency_minutes(data)\n",
        "data['hour'] = data['timestamp'].dt.hour + data['timestamp'].dt.minute / 60\n",
        "data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
        "data['is_weekend'] = data['day_of_week'].isin([5, 6])\n",
        "data['time_of_day'] = data['timestamp'].dt.strftime('%H:%M')\n",
        "print(f'Loaded {len(data):,} rows at a {freq_minutes}-minute cadence.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_forecast(df: pd.DataFrame, freq_minutes: int, history_weeks: int = BASELINE_WEEKS):\n",
        "    df = df.sort_values('timestamp').copy()\n",
        "    freq = pd.Timedelta(minutes=freq_minutes)\n",
        "    last_ts = df['timestamp'].iloc[-1]\n",
        "    horizon_periods = int(pd.Timedelta(days=7) / freq)\n",
        "    future_index = pd.date_range(start=last_ts + freq, periods=horizon_periods, freq=freq)\n",
        "\n",
        "    cutoff = last_ts - pd.Timedelta(weeks=history_weeks) + freq\n",
        "    history = df[df['timestamp'] >= cutoff]\n",
        "    if history.empty:\n",
        "        history = df.copy()\n",
        "\n",
        "    grouped = history.groupby(['day_of_week', 'time_of_day'])['riders'].mean()\n",
        "    default_mean = history['riders'].mean()\n",
        "\n",
        "    records = []\n",
        "    for ts in future_index:\n",
        "        key = (ts.dayofweek, ts.strftime('%H:%M'))\n",
        "        yhat = grouped.get(key, default_mean)\n",
        "        records.append({\n",
        "            'timestamp': ts,\n",
        "            'yhat': yhat,\n",
        "            'day_of_week': ts.dayofweek,\n",
        "            'time_of_day': ts.strftime('%H:%M'),\n",
        "            'is_weekend': ts.dayofweek in (5, 6),\n",
        "            'hour': ts.hour + ts.minute / 60,\n",
        "            'minute_of_day': ts.hour * 60 + ts.minute,\n",
        "        })\n",
        "\n",
        "    forecast_df = pd.DataFrame(records)\n",
        "    forecast_df.to_csv(PROCESSED_PATH / 'forecast.csv', index=False)\n",
        "    return forecast_df, grouped, default_mean\n",
        "\n",
        "\n",
        "forecast_df, baseline_lookup, baseline_mean = build_forecast(data, freq_minutes)\n",
        "print(f'Forecast horizon: {forecast_df[\"timestamp\"].min()} to {forecast_df[\"timestamp\"].max()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def time_to_minutes(value: str) -> int:\n",
        "    hour, minute = map(int, value.split(':'))\n",
        "    return hour * 60 + minute\n",
        "\n",
        "\n",
        "def mark_offpeak(minutes: pd.Series, start_min: int, end_min: int) -> pd.Series:\n",
        "    if start_min <= end_min:\n",
        "        return (minutes >= start_min) & (minutes < end_min)\n",
        "    return (minutes >= start_min) | (minutes < end_min)\n",
        "\n",
        "\n",
        "def simulate_demand(forecast: pd.DataFrame, offpeak_start: str, offpeak_end: str, discount_pct: float, elasticity: float):\n",
        "    df = forecast.copy()\n",
        "    df['baseline'] = df['yhat']\n",
        "    start_min = time_to_minutes(offpeak_start)\n",
        "    end_min = time_to_minutes(offpeak_end)\n",
        "    df['is_offpeak'] = mark_offpeak(df['minute_of_day'], start_min, end_min)\n",
        "    df['is_peak'] = ~df['is_offpeak']\n",
        "\n",
        "    df['after_incentive'] = df['baseline']\n",
        "    df.loc[df['is_offpeak'], 'after_incentive'] = df.loc[df['is_offpeak'], 'baseline'] * (1 + elasticity * discount_pct)\n",
        "\n",
        "    baseline_offpeak = df.loc[df['is_offpeak'], 'baseline'].sum()\n",
        "    baseline_peak = df.loc[df['is_peak'], 'baseline'].sum()\n",
        "    after_offpeak = df.loc[df['is_offpeak'], 'after_incentive'].sum()\n",
        "    delta = after_offpeak - baseline_offpeak\n",
        "\n",
        "    if abs(delta) > 1e-6 and (baseline_peak > 0 or baseline_offpeak > 0):\n",
        "        target_series = df.loc[df['is_peak'], 'baseline'] if baseline_peak > 0 else df.loc[df['is_offpeak'], 'baseline']\n",
        "        target_sum = target_series.sum()\n",
        "        if target_sum > 0:\n",
        "            adjustment = delta * (target_series / target_sum)\n",
        "            adjusted_values = target_series - adjustment\n",
        "            adjusted_values = adjusted_values.clip(lower=0)\n",
        "            df.loc[target_series.index, 'after_incentive'] = adjusted_values\n",
        "\n",
        "    total_baseline = df['baseline'].sum()\n",
        "    total_after = df['after_incentive'].sum()\n",
        "    diff = total_after - total_baseline\n",
        "    if abs(diff) > 1e-6:\n",
        "        peak_mask = df['is_peak'] & (df['after_incentive'] > 0)\n",
        "        target_mask = peak_mask if peak_mask.any() else df['is_offpeak']\n",
        "        target_sum = df.loc[target_mask, 'after_incentive'].sum()\n",
        "        if target_sum > 0:\n",
        "            correction = diff * (df.loc[target_mask, 'after_incentive'] / target_sum)\n",
        "            df.loc[target_mask, 'after_incentive'] -= correction\n",
        "\n",
        "    df.to_csv(PROCESSED_PATH / 'simulation.csv', index=False)\n",
        "\n",
        "    totals_match = math.isclose(df['after_incentive'].sum(), df['baseline'].sum(), rel_tol=1e-6)\n",
        "    peak_reduction_pct = 0.0\n",
        "    if baseline_peak > 0:\n",
        "        after_peak = df.loc[df['is_peak'], 'after_incentive'].sum()\n",
        "        peak_reduction_pct = 100 * (1 - after_peak / baseline_peak)\n",
        "    offpeak_increase_pct = 0.0\n",
        "    if baseline_offpeak > 0:\n",
        "        offpeak_increase_pct = 100 * (after_offpeak / baseline_offpeak - 1)\n",
        "\n",
        "    baseline_revenue = df['baseline'].sum()\n",
        "    after_revenue = df.loc[df['is_peak'], 'after_incentive'].sum()\n",
        "    after_revenue += df.loc[df['is_offpeak'], 'after_incentive'].sum() * (1 - discount_pct)\n",
        "    revenue_change_pct = 100 * (after_revenue / baseline_revenue - 1) if baseline_revenue else 0.0\n",
        "\n",
        "    summary = {\n",
        "        'totals_match': totals_match,\n",
        "        'peak_reduction_pct': peak_reduction_pct,\n",
        "        'offpeak_increase_pct': offpeak_increase_pct,\n",
        "        'revenue_change_pct': revenue_change_pct,\n",
        "    }\n",
        "    return df, summary\n",
        "\n",
        "\n",
        "def render_simulation(offpeak_start: str, offpeak_end: str, discount_pct: float, elasticity: float):\n",
        "    sim_df, summary = simulate_demand(forecast_df, offpeak_start, offpeak_end, discount_pct, elasticity)\n",
        "\n",
        "    print('Summary:')\n",
        "    print(f\" - Total riders unchanged: {'Yes' if summary['totals_match'] else 'No'}\")\n",
        "    print(f\" - Peak hour reduction: {summary['peak_reduction_pct']:.2f}%\")\n",
        "    print(f\" - Off-peak increase: {summary['offpeak_increase_pct']:.2f}%\")\n",
        "    print(f\" - Revenue change: {summary['revenue_change_pct']:.2f}%\")\n",
        "\n",
        "    week_start = sim_df['timestamp'].min()\n",
        "    week_end = week_start + pd.Timedelta(days=7)\n",
        "    week_mask = (sim_df['timestamp'] >= week_start) & (sim_df['timestamp'] < week_end)\n",
        "    week_df = sim_df.loc[week_mask]\n",
        "\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
        "    axes[0].plot(week_df['timestamp'], week_df['baseline'], label='Baseline')\n",
        "    axes[0].plot(week_df['timestamp'], week_df['after_incentive'], label='After incentive')\n",
        "    axes[0].set_title('Baseline vs. After incentive (first week of forecast)')\n",
        "    axes[0].set_ylabel('Riders')\n",
        "    axes[0].legend()\n",
        "\n",
        "    hourly = sim_df.copy()\n",
        "    hourly['hour_of_day'] = hourly['timestamp'].dt.strftime('%H:%M')\n",
        "    grouped = hourly.groupby('hour_of_day')[['baseline', 'after_incentive']].mean()\n",
        "    grouped[['baseline', 'after_incentive']].plot(kind='bar', ax=axes[1])\n",
        "    axes[1].set_title('Average riders by time of day')\n",
        "    axes[1].set_ylabel('Riders')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return sim_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time_options = [f\"{hour:02d}:{minute:02d}\" for hour in range(24) for minute in (0, 15, 30, 45)]\n",
        "offpeak_start_widget = widgets.Dropdown(options=time_options, value='10:00', description='Off-peak start')\n",
        "offpeak_end_widget = widgets.Dropdown(options=time_options, value='16:00', description='Off-peak end')\n",
        "discount_widget = widgets.FloatSlider(min=0.0, max=0.5, step=0.01, value=0.10, description='Discount', readout_format='.0%')\n",
        "elasticity_widget = widgets.FloatSlider(min=-1.0, max=0.0, step=0.01, value=-0.30, description='Elasticity')\n",
        "run_button = widgets.Button(description='Run', button_style='primary')\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "def on_run(_):\n",
        "    with output:\n",
        "        clear_output(wait=True)\n",
        "        render_simulation(\n",
        "            offpeak_start_widget.value,\n",
        "            offpeak_end_widget.value,\n",
        "            discount_widget.value,\n",
        "            elasticity_widget.value,\n",
        "        )\n",
        "\n",
        "\n",
        "run_button.on_click(on_run)\n",
        "controls = widgets.VBox([\n",
        "    widgets.HBox([offpeak_start_widget, offpeak_end_widget]),\n",
        "    discount_widget,\n",
        "    elasticity_widget,\n",
        "    run_button,\n",
        "])\n",
        "display(controls, output)\n",
        "on_run(None)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}